{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aBQeEF7anFD",
        "outputId": "7fb2ad1c-c02b-4559-d1dc-b5f4a15f2d4b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XelE-h6bZkgB"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/Colab Notebooks/MHEALTHDATASET\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def subject_file_name(subject_id):\n",
        "    return DATA_DIR + \"/mHealth_subject\" + str(subject_id) + \".log\"\n",
        "\n",
        "def parse_line(line):\n",
        "    line = line.strip()\n",
        "    if line == \"\":\n",
        "        return None, None #빈줄 무시\n",
        "    parts = line.split()\n",
        "    label_str = parts[-1]\n",
        "    feature_strs = parts[:-1]\n",
        "\n",
        "    features = []\n",
        "    for v in feature_strs:\n",
        "        if v == \"\":\n",
        "            continue\n",
        "        features.append(float(v))\n",
        "\n",
        "    label = int(label_str)\n",
        "\n",
        "    return features, label"
      ],
      "metadata": {
        "id": "ANV8dD0obDDU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "subjects = []\n",
        "\n",
        "for sid in range(1, 11):\n",
        "    file_path = subject_file_name(sid)\n",
        "    print(\"Reading subject\", sid, \"from\", file_path)\n",
        "\n",
        "    try:\n",
        "        f = open(file_path, \"r\")\n",
        "    except:\n",
        "        print(\"err\")\n",
        "        continue\n",
        "\n",
        "    line_count = 0\n",
        "    sample_count = 0\n",
        "\n",
        "    while True:\n",
        "        line = f.readline()\n",
        "        if not line:\n",
        "            break\n",
        "\n",
        "        line_count += 1\n",
        "        features, label = parse_line(line)\n",
        "\n",
        "        if features is None:\n",
        "            continue\n",
        "\n",
        "        X.append(features)\n",
        "        y.append(label)\n",
        "        subjects.append(sid)\n",
        "        sample_count += 1\n",
        "\n",
        "    f.close()\n",
        "    print(\"  lines:\", line_count, \" -> samples:\", sample_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H99745oMbKvD",
        "outputId": "b853530c-b5a1-4e24-f4e8-361ff57ef1f8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading subject 1 from /content/drive/MyDrive/Colab Notebooks/MHEALTHDATASET/mHealth_subject1.log\n",
            "  lines: 161280  -> samples: 161280\n",
            "Reading subject 2 from /content/drive/MyDrive/Colab Notebooks/MHEALTHDATASET/mHealth_subject2.log\n",
            "  lines: 130561  -> samples: 130561\n",
            "Reading subject 3 from /content/drive/MyDrive/Colab Notebooks/MHEALTHDATASET/mHealth_subject3.log\n",
            "  lines: 122112  -> samples: 122112\n",
            "Reading subject 4 from /content/drive/MyDrive/Colab Notebooks/MHEALTHDATASET/mHealth_subject4.log\n",
            "  lines: 116736  -> samples: 116736\n",
            "Reading subject 5 from /content/drive/MyDrive/Colab Notebooks/MHEALTHDATASET/mHealth_subject5.log\n",
            "  lines: 119808  -> samples: 119808\n",
            "Reading subject 6 from /content/drive/MyDrive/Colab Notebooks/MHEALTHDATASET/mHealth_subject6.log\n",
            "  lines: 98304  -> samples: 98304\n",
            "Reading subject 7 from /content/drive/MyDrive/Colab Notebooks/MHEALTHDATASET/mHealth_subject7.log\n",
            "  lines: 104448  -> samples: 104448\n",
            "Reading subject 8 from /content/drive/MyDrive/Colab Notebooks/MHEALTHDATASET/mHealth_subject8.log\n",
            "  lines: 129024  -> samples: 129024\n",
            "Reading subject 9 from /content/drive/MyDrive/Colab Notebooks/MHEALTHDATASET/mHealth_subject9.log\n",
            "  lines: 135168  -> samples: 135168\n",
            "Reading subject 10 from /content/drive/MyDrive/Colab Notebooks/MHEALTHDATASET/mHealth_subject10.log\n",
            "  lines: 98304  -> samples: 98304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"총 샘플:\", len(X))\n",
        "print(\"피처(feature dimension):\", len(X[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_i0inTgbe8i",
        "outputId": "364457ee-4a6c-42e7-8f96-f5634c2e1454"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 샘플: 1215745\n",
            "피처(feature dimension): 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels = []\n",
        "for v in y:\n",
        "    if v not in unique_labels:\n",
        "        unique_labels.append(v)\n",
        "\n",
        "print(\"라벨 종류:\", unique_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFEUomCOdTCr",
        "outputId": "c9851961-1540-48b8-aa90-6b8084684905"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "라벨 종류: [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_folds():\n",
        "    return [[1, 2],[3, 4],[5, 6],[7, 8],[9, 10]]\n",
        "\n",
        "def split_by_subjects(X, y, subjects, test_subjects):\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    X_test  = []\n",
        "    y_test  = []\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        s = subjects[i]\n",
        "        if s in test_subjects:\n",
        "            X_test.append(X[i])\n",
        "            y_test.append(y[i])\n",
        "        else:\n",
        "            X_train.append(X[i])\n",
        "            y_train.append(y[i])\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "DuSARA0VdbHT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folds = make_folds()\n",
        "for idx in range(len(folds)):\n",
        "    ts = folds[idx]\n",
        "    X_tr, y_tr, X_te, y_te = split_by_subjects(X, y, subjects, ts)\n",
        "    print(\"Fold\", idx+1, \" | test subjects =\", ts,\n",
        "          \" | train samples:\", len(X_tr),\n",
        "          \" | test samples:\", len(X_te))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKsBeiHdqGZZ",
        "outputId": "5ee234f9-c810-4ae3-afe2-29fa522559b0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1  | test subjects = [1, 2]  | train samples: 923904  | test samples: 291841\n",
            "Fold 2  | test subjects = [3, 4]  | train samples: 976897  | test samples: 238848\n",
            "Fold 3  | test subjects = [5, 6]  | train samples: 997633  | test samples: 218112\n",
            "Fold 4  | test subjects = [7, 8]  | train samples: 982273  | test samples: 233472\n",
            "Fold 5  | test subjects = [9, 10]  | train samples: 982273  | test samples: 233472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels_union(y_true, y_pred):\n",
        "    labels = []\n",
        "\n",
        "    for v in y_true:\n",
        "      if v not in labels:\n",
        "        labels.append(v)\n",
        "\n",
        "    for v in y_pred:\n",
        "      if v not in labels:\n",
        "        labels.append(v)\n",
        "\n",
        "    return labels"
      ],
      "metadata": {
        "id": "ba0RJkjXqQZF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Macro, F1 calc"
      ],
      "metadata": {
        "id": "C_8yJxVlruQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def macro_f1_score(y_true, y_pred):\n",
        "  labels = get_labels_union(y_true, y_pred)\n",
        "\n",
        "  TP = {}\n",
        "  FP = {}\n",
        "  FN = {}\n",
        "  for c in labels:\n",
        "      TP[c] = 0\n",
        "      FP[c] = 0\n",
        "      FN[c] = 0\n",
        "\n",
        "  for i in range(len(y_true)):\n",
        "      t = y_true[i]\n",
        "      p = y_pred[i]\n",
        "\n",
        "      for c in labels:\n",
        "        if p == c and t == c:\n",
        "          TP[c] += 1\n",
        "        elif p == c and t != c:\n",
        "          FP[c] += 1\n",
        "        elif p != c and t == c:\n",
        "          FN[c] += 1\n",
        "\n",
        "  f1_sum = 0.0\n",
        "  count = 0\n",
        "\n",
        "  for c in labels:\n",
        "    tp = TP[c]\n",
        "    fp = FP[c]\n",
        "    fn = FN[c]\n",
        "\n",
        "    if tp == 0 and fp == 0 and fn == 0:\n",
        "      continue\n",
        "\n",
        "    # precision, recall\n",
        "    if tp + fp == 0:\n",
        "        precision = 0.0\n",
        "    else:\n",
        "        precision = tp / float(tp + fp)\n",
        "\n",
        "    if tp + fn == 0:\n",
        "        recall = 0.0\n",
        "    else:\n",
        "        recall = tp / float(tp + fn)\n",
        "\n",
        "    if precision == 0.0 and recall == 0.0:\n",
        "        f1 = 0.0\n",
        "    else:\n",
        "        f1 = 2.0 * precision * recall / (precision + recall)\n",
        "\n",
        "    f1_sum += f1\n",
        "    count += 1\n",
        "\n",
        "    if count == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return f1_sum / float(count)"
      ],
      "metadata": {
        "id": "AON2NAvvrnfz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW = 128\n",
        "STRIDE = 64\n",
        "\n",
        "def create_windows(X, y, subjects, window_size=128, stride=64):\n",
        "    N = len(X)\n",
        "    D = len(X[0])\n",
        "\n",
        "    Xw = []\n",
        "    yw = []\n",
        "    sw = []\n",
        "\n",
        "    i = 0\n",
        "    while i + window_size <= N:\n",
        "        win = []\n",
        "        for t in range(window_size):\n",
        "            win.append(X[i + t])\n",
        "\n",
        "        mid = i + window_size // 2\n",
        "        label = y[mid]\n",
        "        subject_id = subjects[mid]\n",
        "\n",
        "        Xw.append(win)\n",
        "        yw.append(label)\n",
        "        sw.append(subject_id)\n",
        "\n",
        "        i += stride\n",
        "    return Xw, yw, sw\n",
        "\n",
        "Xw, yw, sw = create_windows(X, y, subjects, window_size=WINDOW, stride=STRIDE)\n",
        "print(\"윈도우 개수:\", len(Xw))\n",
        "print(\"윈도우 shape:\", len(Xw[0]), \"x\", len(Xw[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0OZIMdtsPVS",
        "outputId": "c0ca6727-e389-4b0b-925c-0ba6e454835f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "윈도우 개수: 18995\n",
            "윈도우 shape: 128 x 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FORWARD"
      ],
      "metadata": {
        "id": "arl5gt3wzfnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv1D:\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "        self.W = []\n",
        "        for f in range(out_channels):\n",
        "            kernel = []\n",
        "            for k in range(kernel_size):\n",
        "                row = []\n",
        "                for c in range(in_channels):\n",
        "                    row.append(((f+1)*(k+2)*(c+3) % 17) * 0.001)\n",
        "                kernel.append(row)\n",
        "            self.W.append(kernel)\n",
        "\n",
        "        self.b = [0.0] * out_channels\n",
        "\n",
        "        self.last_x = None\n",
        "        self.grad_W = None\n",
        "        self.grad_b = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.last_x = x\n",
        "\n",
        "        T = len(x)\n",
        "        K = self.kernel_size\n",
        "        C = self.in_channels\n",
        "        F = self.out_channels\n",
        "\n",
        "        out_T = T - K + 1\n",
        "\n",
        "        out = []\n",
        "        for t in range(out_T):\n",
        "            row = []\n",
        "            for f in range(F):\n",
        "                s = self.b[f]\n",
        "                kernel = self.W[f]\n",
        "\n",
        "                for k in range(K):\n",
        "                    xi = x[t + k]\n",
        "                    wi = kernel[k]\n",
        "                    for c in range(C):\n",
        "                        s += xi[c] * wi[c]\n",
        "                row.append(s)\n",
        "            out.append(row)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, grad_out):\n",
        "        x = self.last_x\n",
        "        T = len(x)\n",
        "        C = self.in_channels\n",
        "        F = self.out_channels\n",
        "        K = self.kernel_size\n",
        "\n",
        "        out_T = T - K + 1\n",
        "\n",
        "        self.grad_W = []\n",
        "        for f in range(F):\n",
        "            kernel_grad = []\n",
        "            for k in range(K):\n",
        "                kernel_grad.append([0.0] * C)\n",
        "            self.grad_W.append(kernel_grad)\n",
        "\n",
        "        self.grad_b = [0.0] * F\n",
        "\n",
        "        grad_x = []\n",
        "        for t in range(T):\n",
        "            grad_x.append([0.0] * C)\n",
        "\n",
        "        for t in range(out_T):\n",
        "            for f in range(F):\n",
        "                go = grad_out[t][f]\n",
        "\n",
        "                self.grad_b[f] += go\n",
        "\n",
        "                for k in range(K):\n",
        "                    xi = x[t + k]\n",
        "                    for c in range(C):\n",
        "                        self.grad_W[f][k][c] += xi[c] * go\n",
        "\n",
        "                for k in range(K):\n",
        "                    wi = self.W[f][k]\n",
        "                    for c in range(C):\n",
        "                        grad_x[t + k][c] += wi[c] * go\n",
        "        return grad_x"
      ],
      "metadata": {
        "id": "6c-tQ-SQzDaV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReLU"
      ],
      "metadata": {
        "id": "i7Si7Vurz1e4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "    def __init__(self):\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        T = len(x)\n",
        "        C = len(x[0])\n",
        "\n",
        "        out = []\n",
        "        self.mask = []\n",
        "\n",
        "        for t in range(T):\n",
        "            row = []\n",
        "            mask_row = []\n",
        "            for c in range(C):\n",
        "                if x[t][c] > 0:\n",
        "                    row.append(x[t][c])\n",
        "                    mask_row.append(1)\n",
        "                else:\n",
        "                    row.append(0.0)\n",
        "                    mask_row.append(0)\n",
        "            out.append(row)\n",
        "            self.mask.append(mask_row)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, grad_out):\n",
        "        T = len(grad_out)\n",
        "        C = len(grad_out[0])\n",
        "\n",
        "        grad_in = []\n",
        "\n",
        "        for t in range(T):\n",
        "            row = []\n",
        "            for c in range(C):\n",
        "                if self.mask[t][c] == 1:\n",
        "                    row.append(grad_out[t][c])\n",
        "                else:\n",
        "                    row.append(0.0)\n",
        "            grad_in.append(row)\n",
        "\n",
        "        return grad_in"
      ],
      "metadata": {
        "id": "ltl3SQhzzoCi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relu = ReLU()\n",
        "x = [[-1, 2], [3, -4]]\n",
        "\n",
        "out = relu.forward(x)\n",
        "print(\"forward:\", out)\n",
        "grad_out = [[1,1],[1,1]]\n",
        "gx = relu.backward(grad_out)\n",
        "print(\"backward:\", gx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3Z0LGAez4Lf",
        "outputId": "17a3e88a-5799-42a4-c31c-d01ccf4f0c77"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward: [[0.0, 2], [3, 0.0]]\n",
            "backward: [[0.0, 1], [1, 0.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GAP"
      ],
      "metadata": {
        "id": "LvFjvbbE0JQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GAP:\n",
        "    def __init__(self):\n",
        "        self.T = None\n",
        "        self.C = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.T = len(x)\n",
        "        self.C = len(x[0])\n",
        "\n",
        "        out = []\n",
        "\n",
        "        for c in range(self.C):\n",
        "            s = 0.0\n",
        "            for t in range(self.T):\n",
        "                s += x[t][c]\n",
        "            out.append(s / float(self.T))\n",
        "        return out\n",
        "\n",
        "    def backward(self, grad_out):\n",
        "        grad_in = []\n",
        "        for t in range(self.T):\n",
        "            row = []\n",
        "            for c in range(self.C):\n",
        "                row.append(grad_out[c] / float(self.T))\n",
        "            grad_in.append(row)\n",
        "        return grad_in"
      ],
      "metadata": {
        "id": "IABUNt1v0FeV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gap = GAP()\n",
        "\n",
        "x = [\n",
        "    [1, 4],\n",
        "    [2, 5],\n",
        "    [3, 6]\n",
        "]\n",
        "\n",
        "out = gap.forward(x)\n",
        "print(\"GAP forward:\", out)\n",
        "grad_out = [3, 6]\n",
        "\n",
        "gx = gap.backward(grad_out)\n",
        "print(\"GAP backward:\", gx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1ek8N1d0PO9",
        "outputId": "1df6bbdd-199b-458f-9357-9a700b3249fe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAP forward: [2.0, 5.0]\n",
            "GAP backward: [[1.0, 2.0], [1.0, 2.0], [1.0, 2.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FC(full connection)\n",
        "\n",
        "loss = -log( exp(score[label]) / sum(exp(score)) )"
      ],
      "metadata": {
        "id": "2ghG-CPa0iJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_exp(x):\n",
        "    return 1.0 + x + (x*x)/2.0 + (x*x*x)/6.0\n",
        "\n",
        "def softmax(scores):\n",
        "    mx = scores[0]\n",
        "    for s in scores:\n",
        "        if s > mx:\n",
        "            mx = s\n",
        "\n",
        "    exps = []\n",
        "    ssum = 0.0\n",
        "    for s in scores:\n",
        "        e = my_exp(s - mx)\n",
        "        exps.append(e)\n",
        "        ssum += e\n",
        "\n",
        "    out = []\n",
        "    for e in exps:\n",
        "        out.append(e / ssum)\n",
        "    return out\n",
        "\n",
        "\n",
        "def cross_entropy(softmax_probs, target_label):\n",
        "    p = softmax_probs[target_label]\n",
        "    if p <= 1e-12:\n",
        "        p = 1e-12\n",
        "    return - (0.0 + my_log(p))\n",
        "\n",
        "def my_log(x):\n",
        "    y = x - 1.0\n",
        "    return y - (y*y)/2.0 + (y*y*y)/3.0\n",
        "\n",
        "## FC layer\n",
        "class FC:\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "\n",
        "        self.W = []\n",
        "        for i in range(in_dim):\n",
        "            row = []\n",
        "            for j in range(out_dim):\n",
        "                row.append( ( (i * 97 + j * 13) % 100 ) / 5000.0 - 0.01 )\n",
        "            self.W.append(row)\n",
        "\n",
        "        self.b = []\n",
        "        for j in range(out_dim):\n",
        "            self.b.append(0.0)\n",
        "\n",
        "        self.x = None\n",
        "        self.grad_W = None\n",
        "        self.grad_b = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "\n",
        "        out = []\n",
        "        for j in range(self.out_dim):\n",
        "            s = self.b[j]\n",
        "            for i in range(self.in_dim):\n",
        "                s += self.W[i][j] * x[i]\n",
        "            out.append(s)\n",
        "        return out\n",
        "\n",
        "    def backward(self, grad_out):\n",
        "        self.grad_W = []\n",
        "        for i in range(self.in_dim):\n",
        "            row = []\n",
        "            for j in range(self.out_dim):\n",
        "                row.append(self.x[i] * grad_out[j])\n",
        "            self.grad_W.append(row)\n",
        "\n",
        "        self.grad_b = []\n",
        "        for j in range(self.out_dim):\n",
        "            self.grad_b.append(grad_out[j])\n",
        "\n",
        "        grad_in = []\n",
        "        for i in range(self.in_dim):\n",
        "            s = 0.0\n",
        "            for j in range(self.out_dim):\n",
        "                s += self.W[i][j] * grad_out[j]\n",
        "            grad_in.append(s)\n",
        "        return grad_in"
      ],
      "metadata": {
        "id": "F-6dCj8V0aV4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SoftMax, SGD"
      ],
      "metadata": {
        "id": "9kt3uhEr1HOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_cross_entropy_backward(softmax_probs, target_label):\n",
        "    num_classes = len(softmax_probs)\n",
        "    grad_scores = []\n",
        "\n",
        "    for j in range(num_classes):\n",
        "        if j == target_label:\n",
        "            grad_scores.append(softmax_probs[j] - 1.0)\n",
        "        else:\n",
        "            grad_scores.append(softmax_probs[j])\n",
        "\n",
        "    return grad_scores\n",
        "\n",
        "def sgd_update(params, grads, lr):\n",
        "    if isinstance(params[0], list):\n",
        "        if isinstance(params[0][0], list):\n",
        "            for i in range(len(params)):\n",
        "                for j in range(len(params[i])):\n",
        "                    for k_dim in range(len(params[i][j])):\n",
        "                        params[i][j][k_dim] -= lr * grads[i][j][k_dim]\n",
        "        else:\n",
        "            for i in range(len(params)):\n",
        "                for j in range(len(params[i])):\n",
        "                    params[i][j] -= lr * grads[i][j]\n",
        "    else:\n",
        "        for i in range(len(params)):\n",
        "            params[i] -= lr * grads[i]"
      ],
      "metadata": {
        "id": "t6Lb7bIJ0-vG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN ASSEMBLE"
      ],
      "metadata": {
        "id": "7AF_XDZ31gja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel:\n",
        "    def __init__(self, in_channels=23, num_classes=13, hidden_channels=16):\n",
        "        self.conv1 = Conv1D(in_channels, hidden_channels, kernel_size=3)\n",
        "        self.relu1 = ReLU()\n",
        "        self.conv2 = Conv1D(hidden_channels, hidden_channels, kernel_size=3)\n",
        "        self.relu2 = ReLU()\n",
        "        self.gap = GAP()\n",
        "        self.fc = FC(hidden_channels, num_classes)\n",
        "\n",
        "        self.last_softmax = None\n",
        "        self.last_scores = None\n",
        "        self.last_label = None\n",
        "\n",
        "    def forward(self, x, label):\n",
        "        out = self.conv1.forward(x)\n",
        "        out = self.relu1.forward(out)\n",
        "        out = self.conv2.forward(out)\n",
        "        out = self.relu2.forward(out)\n",
        "        out = self.gap.forward(out)\n",
        "\n",
        "        scores = self.fc.forward(out)\n",
        "\n",
        "        probs = softmax(scores)\n",
        "\n",
        "        loss = -my_log(probs[label])\n",
        "\n",
        "        self.last_label = label\n",
        "        self.last_scores = scores\n",
        "        self.last_softmax = probs\n",
        "\n",
        "        return loss, probs\n",
        "\n",
        "    def backward(self):\n",
        "        label = self.last_label\n",
        "        probs = self.last_softmax\n",
        "        scores = self.last_scores\n",
        "\n",
        "        grad_scores = softmax_cross_entropy_backward(probs, label)\n",
        "        grad_fc = self.fc.backward(grad_scores)\n",
        "        grad_gap = self.gap.backward(grad_fc)\n",
        "        grad_relu2 = self.relu2.backward(grad_gap)\n",
        "        grad_conv2 = self.conv2.backward(grad_relu2)\n",
        "        grad_relu1 = self.relu1.backward(grad_conv2)\n",
        "        grad_conv1 = self.conv1.backward(grad_relu1)\n",
        "\n",
        "    def step(self, lr):\n",
        "        sgd_update(self.conv1.W, self.conv1.grad_W, lr)\n",
        "        sgd_update(self.conv1.b, self.conv1.grad_b, lr)\n",
        "\n",
        "        sgd_update(self.conv2.W, self.conv2.grad_W, lr)\n",
        "        sgd_update(self.conv2.b, self.conv2.grad_b, lr)\n",
        "\n",
        "        sgd_update(self.fc.W, self.fc.grad_W, lr)\n",
        "        sgd_update(self.fc.b, self.fc.grad_b, lr)"
      ],
      "metadata": {
        "id": "_yCwLxMA1TXE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNNModel()"
      ],
      "metadata": {
        "id": "EVQkzK9l1zns"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_x = Xw[0]\n",
        "sample_label = yw[0]\n",
        "\n",
        "loss, probs = model.forward(sample_x, sample_label)\n",
        "model.backward()\n",
        "model.step(lr=0.001)\n",
        "\n",
        "print(\"loss:\", loss)\n",
        "print(\"probs:\", probs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Oyh4BmS3Hpj",
        "outputId": "05223fec-f972-44dc-ce3b-c02da1b41f9e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 1.6112880895942328\n",
            "probs: [0.07692308793857167, 0.07692307955698345, 0.07692307324465489, 0.07692306780359363, 0.07692307053065872, 0.07692307630715792, 0.07692308208365757, 0.07692308786015764, 0.0769230855774381, 0.07692307817602541, 0.07692307044788838, 0.07692306816516936, 0.07692307230804304]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_batches(Xw, yw, batch_size):\n",
        "    batches = []\n",
        "    N = len(Xw)\n",
        "\n",
        "    i = 0\n",
        "    while i < N:\n",
        "        bx = Xw[i:i+batch_size]\n",
        "        by = yw[i:i+batch_size]\n",
        "        batches.append((bx, by))\n",
        "        i += batch_size\n",
        "\n",
        "    return batches"
      ],
      "metadata": {
        "id": "8epH9GEQ3PU0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_windows_by_subjects(Xw, yw, sw, test_subjects):\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    X_test = []\n",
        "    y_test = []\n",
        "\n",
        "    for i in range(len(Xw)):\n",
        "        subj = sw[i]\n",
        "        if subj in test_subjects:\n",
        "            X_test.append(Xw[i])\n",
        "            y_test.append(yw[i])\n",
        "        else:\n",
        "            X_train.append(Xw[i])\n",
        "            y_train.append(yw[i])\n",
        "\n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "JoMkg6L94LC8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, batches, lr):\n",
        "    total_loss = 0.0\n",
        "    count = 0\n",
        "    total_samples = sum(len(bx) for (bx, by) in batches)\n",
        "\n",
        "    processed = 0\n",
        "\n",
        "    for (bx, by) in batches:\n",
        "        for i in range(len(bx)):\n",
        "            x = bx[i]\n",
        "            label = by[i]\n",
        "\n",
        "            loss, probs = model.forward(x, label)\n",
        "            model.backward()\n",
        "            model.step(lr)\n",
        "\n",
        "            total_loss += loss\n",
        "            count += 1\n",
        "            processed += 1\n",
        "\n",
        "            bar_size = 20\n",
        "            ratio = processed / total_samples\n",
        "            filled = int(ratio * bar_size)\n",
        "            bar = \"[\" + \"=\" * filled + \">\" + \".\" * (bar_size - filled) + \"]\"\n",
        "\n",
        "            print(\n",
        "                f\"\\r {processed}/{total_samples} {bar} {ratio*100:5.1f}%\",\n",
        "                end=\"\"\n",
        "            )\n",
        "\n",
        "    print()\n",
        "    return total_loss / count\n",
        "\n",
        "def predict(model, x):\n",
        "    _, probs = model.forward(x, 0)\n",
        "    best = 0\n",
        "    best_val = probs[0]\n",
        "    for i in range(len(probs)):\n",
        "        if probs[i] > best_val:\n",
        "            best_val = probs[i]\n",
        "            best = i\n",
        "    return best\n",
        "\n",
        "def evaluate_model(model, Xw_test, yw_test):\n",
        "    preds = []\n",
        "    for i in range(len(Xw_test)):\n",
        "        pred = predict(model, Xw_test[i])\n",
        "        preds.append(pred)\n",
        "    return macro_f1_score(yw_test, preds)"
      ],
      "metadata": {
        "id": "l_LxNaYU4OQb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_5fold_CNN(Xw, yw, sw, epochs=1, batch_size=8, lr=0.001):\n",
        "    folds = [[1, 2],[3, 4],[5, 6],[7, 8],[9, 10]]\n",
        "    fold_f1_scores = []\n",
        "\n",
        "    for fold_idx in range(5):\n",
        "        test_subjects = folds[fold_idx]\n",
        "\n",
        "        Xw_train = []\n",
        "        yw_train = []\n",
        "        Xw_test = []\n",
        "        yw_test = []\n",
        "\n",
        "        for i in range(len(Xw)):\n",
        "            if sw[i] in test_subjects:\n",
        "                Xw_test.append(Xw[i])\n",
        "                yw_test.append(yw[i])\n",
        "            else:\n",
        "                Xw_train.append(Xw[i])\n",
        "                yw_train.append(yw[i])\n",
        "\n",
        "        print(\"===== Fold\", fold_idx+1, \"test subjects =\", test_subjects, \"=====\")\n",
        "        print(\"train windows:\", len(Xw_train), \" | test windows:\", len(Xw_test))\n",
        "\n",
        "        batches = make_batches(Xw_train, yw_train, batch_size)\n",
        "        model = CNNModel()\n",
        "\n",
        "        for ep in range(epochs):\n",
        "            avg_loss = train_one_epoch(model, batches, lr)\n",
        "            print(\"Epoch\", ep+1, \"avg_loss:\", avg_loss)\n",
        "\n",
        "        f1 = evaluate_model(model, Xw_test, yw_test)\n",
        "        print(\"Fold F1:\", f1)\n",
        "        fold_f1_scores.append(f1)\n",
        "    mean_f1 = sum(fold_f1_scores) / len(fold_f1_scores)\n",
        "\n",
        "    print(\"====================================\")\n",
        "    print(\"Fold F1 scores:\", fold_f1_scores)\n",
        "    print(\"Mean F1:\", mean_f1)\n",
        "\n",
        "    return fold_f1_scores, mean_f1"
      ],
      "metadata": {
        "id": "pz9cplU-4RLx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_scores, meanf = run_5fold_CNN(Xw, yw, sw, epochs = 1,batch_size = 8,lr = 0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htJc949A4Z91",
        "outputId": "6e9fea00-a67b-4ae1-d078-7bb8c1f8d05d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Fold 1 test subjects = [1, 2] =====\n",
            "train windows: 14435  | test windows: 4560\n",
            " 14435/14435 [====================>] 100.0%\n",
            "Epoch 1 avg_loss: nan\n",
            "Fold F1: 0.8619915148490143\n",
            "===== Fold 2 test subjects = [3, 4] =====\n",
            "train windows: 15263  | test windows: 3732\n",
            " 15263/15263 [====================>] 100.0%\n",
            "Epoch 1 avg_loss: nan\n",
            "Fold F1: 0.8264150943396227\n",
            "===== Fold 3 test subjects = [5, 6] =====\n",
            "train windows: 15587  | test windows: 3408\n",
            " 15587/15587 [====================>] 100.0%\n",
            "Epoch 1 avg_loss: nan\n",
            "Fold F1: 0.8215767634854771\n",
            "===== Fold 4 test subjects = [7, 8] =====\n",
            "train windows: 15347  | test windows: 3648\n",
            " 15347/15347 [====================>] 100.0%\n",
            "Epoch 1 avg_loss: nan\n",
            "Fold F1: 0.8307692307692308\n",
            "===== Fold 5 test subjects = [9, 10] =====\n",
            "train windows: 15348  | test windows: 3647\n",
            " 15348/15348 [====================>] 100.0%\n",
            "Epoch 1 avg_loss: nan\n",
            "Fold F1: 0.8299647096567212\n",
            "====================================\n",
            "Fold F1 scores: [0.8619915148490143, 0.8264150943396227, 0.8215767634854771, 0.8307692307692308, 0.8299647096567212]\n",
            "Mean F1: 0.8341434626200133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ktqTAHVS4gbW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}